{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from dataset import get_2D_normalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNN:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.params = {}\n",
    "        self.params['W1'] = np.random.randn(input_size, hidden_size) / np.sqrt(input_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = np.random.randn(hidden_size, output_size) / np.sqrt(hidden_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.h1 = np.maximum(0, np.dot(X, self.params['W1']) + self.params['b1'])\n",
    "        scores = np.dot(self.h1, self.params['W2']) + self.params['b2']\n",
    "        return scores\n",
    "\n",
    "    def loss(self, X, y, reg):\n",
    "        scores = self.forward(X)\n",
    "\n",
    "        exp_scores = np.exp(scores)\n",
    "        probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "\n",
    "        correct_logprobs = -np.log(probs[range(X.shape[0]),y])\n",
    "        data_loss = np.sum(correct_logprobs) / X.shape[0]\n",
    "        reg_loss = 0.5 * reg * np.sum(self.params['W1'] * self.params['W1']) + 0.5 * reg * np.sum(self.params['W2'] * self.params['W2'])\n",
    "        loss = data_loss + reg_loss\n",
    "        return loss\n",
    "\n",
    "    def train(self, X, y, learning_rate=1e-3, reg=1e-5, num_epochs=100, batch_size=200, verbose=True, early_stop=False, patience=5, tol=1e-3):\n",
    "        num_train = X.shape[0]\n",
    "        iterations_per_epoch = max(num_train // batch_size, 1)\n",
    "        best_loss = float('inf')\n",
    "        count = 0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            for iteration in range(iterations_per_epoch):\n",
    "                batch_indices = np.random.choice(num_train, batch_size, replace=False)\n",
    "                X_batch = X[batch_indices]\n",
    "                y_batch = y[batch_indices]\n",
    "\n",
    "                scores = self.forward(X_batch)\n",
    "\n",
    "                exp_scores = np.exp(scores)\n",
    "                probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "\n",
    "                dscores = probs\n",
    "                dscores[range(batch_size),y_batch] -= 1\n",
    "                dscores /= batch_size\n",
    "\n",
    "                dW2 = np.dot(self.h1.T, dscores)\n",
    "                db2 = np.sum(dscores, axis=0, keepdims=True)\n",
    "\n",
    "                dh1 = np.dot(dscores, self.params['W2'].T)\n",
    "                dh1[self.h1 <= 0] = 0\n",
    "\n",
    "                dW1 = np.dot(X_batch.T, dh1)\n",
    "                db1 = np.sum(dh1, axis=0, keepdims=True)\n",
    "\n",
    "                dW2 += reg * self.params['W2']\n",
    "                dW1 += reg * self.params['W1']\n",
    "\n",
    "                self.params['W1'] -= learning_rate * dW1\n",
    "                self.params['b1'] -= learning_rate * db1.ravel()\n",
    "                self.params['W2'] -= learning_rate * dW2\n",
    "                self.params['b2'] -= learning_rate * db2.ravel()\n",
    "\n",
    "            if verbose and epoch % 10 == 0:\n",
    "                loss = self.loss(X, y, reg)\n",
    "                print(\"Epoch {}, loss = {:.4f}\".format(epoch, loss))\n",
    "\n",
    "            if early_stop:\n",
    "                loss = self.loss(X, y, reg)\n",
    "                if loss < best_loss - tol:\n",
    "                    best_loss = loss\n",
    "                    count = 0\n",
    "                else:\n",
    "                    count += 1\n",
    "\n",
    "                if count == patience:\n",
    "                    print(\"Early stopping: no improvement for {} epochs\".format(patience))\n",
    "                    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = get_2D_normalised()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss = 1.9829\n",
      "Epoch 10, loss = 1.6903\n",
      "Epoch 20, loss = 1.6011\n",
      "Epoch 30, loss = 1.5633\n",
      "Epoch 40, loss = 1.4857\n",
      "Epoch 50, loss = 1.4577\n",
      "Epoch 60, loss = 1.4247\n",
      "Epoch 70, loss = 1.3948\n",
      "Epoch 80, loss = 1.3732\n",
      "Early stopping: no improvement for 5 epochs\n",
      "Test accuracy: 0.4754\n"
     ]
    }
   ],
   "source": [
    "input_size = x_train.shape[1]\n",
    "hidden_size = 50\n",
    "output_size = 10\n",
    "\n",
    "net = TwoLayerNN(input_size, hidden_size, output_size)\n",
    "\n",
    "net.train(x_train, y_train, learning_rate=1e-2, reg=1e-4, num_epochs=100, batch_size=200, verbose=True, early_stop=True, patience=5, tol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.4754\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "test_acc = (np.argmax(net.forward(x_test), axis=1) == y_test).mean()\n",
    "print(\"Test accuracy: {:.4f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
